{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(archived=True, author='halftone84', author_cakeday=None, author_flair_css_class=None, author_flair_text=None, body='I read the title and thought of that cheating bitch clown from the glassjaw video', body_html=None, controversiality=0, created=None, created_utc='1309478410', distinguished=None, downs=0, edited='false', gilded=0, id='c22x4bc', link_id='t3_idgji', mod_reports=None, name='t1_c22x4bc', parent_id='t3_idgji', removal_reason=None, replies=None, retrieved_on=1427302517, saved=None, score=1, score_hidden=False, stickied=None, subreddit='AskReddit', subreddit_id='t5_2qh1i', ups=1, user_reports=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'hdfs://orion11:14001/reddit/sampled_reddit'\n",
    "df = spark.read.json(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archived',\n",
       " 'author',\n",
       " 'author_cakeday',\n",
       " 'author_flair_css_class',\n",
       " 'author_flair_text',\n",
       " 'body',\n",
       " 'body_html',\n",
       " 'controversiality',\n",
       " 'created',\n",
       " 'created_utc',\n",
       " 'distinguished',\n",
       " 'downs',\n",
       " 'edited',\n",
       " 'gilded',\n",
       " 'id',\n",
       " 'link_id',\n",
       " 'mod_reports',\n",
       " 'name',\n",
       " 'parent_id',\n",
       " 'removal_reason',\n",
       " 'replies',\n",
       " 'retrieved_on',\n",
       " 'saved',\n",
       " 'score',\n",
       " 'score_hidden',\n",
       " 'stickied',\n",
       " 'subreddit',\n",
       " 'subreddit_id',\n",
       " 'ups',\n",
       " 'user_reports']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('reddit_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|        subreddit|                body|\n",
      "+-----------------+--------------------+\n",
      "|        AskReddit|I read the title ...|\n",
      "|        AskReddit|Because you're ab...|\n",
      "|         politics|All he had was a ...|\n",
      "|        AskReddit|Flushing with you...|\n",
      "|             IAmA|I grew up in Texa...|\n",
      "|       California|I did this alread...|\n",
      "|             pics|Ctrl-F: *drr* *dr...|\n",
      "|       reddit.com|Damn. I was wrong...|\n",
      "|        AskReddit|          Me too. :/|\n",
      "|        AskReddit|I don't know, but...|\n",
      "|           trance|How did you do that?|\n",
      "|           google|I can haz google+...|\n",
      "|             IAmA|Months?  That's a...|\n",
      "|         sandiego|Is that the Reddi...|\n",
      "|       googleplus|I got my invite, ...|\n",
      "|       technology|This sounds bette...|\n",
      "|        worldnews|Israel handled it...|\n",
      "|DrawingFromWithin|Yeah, I'm ruler g...|\n",
      "|           gaming|I just found out ...|\n",
      "|       reddit.com|Hope you can't wa...|\n",
      "+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "  subreddit, \n",
    "  body\n",
    "FROM\n",
    "  reddit_data\n",
    "WHERE\n",
    "  body != \"[deleted]\"\n",
    "'''\n",
    "text_all = spark.sql(query)\n",
    "text_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_all.coalesce(1).write.format('com.databricks.spark.csv').option('header', 'true').save('hdfs://orion11:14001/output/reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "\n",
    "import bz2\n",
    "import json\n",
    "import sys\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "# commentCount = 0\n",
    "\n",
    "def analyze_sentiment(row): \n",
    "    \n",
    "    # line = bz_file.readline().decode('utf8')\n",
    "#     if len(line) == 0:\n",
    "#         return\n",
    "        \n",
    "#     comment = json.loads(line)\n",
    "#     print(row)\n",
    "    subreddit = row[\"subreddit\"]\n",
    "    body = row[\"body\"]\n",
    "\n",
    "    # variables to hold the overall average compound score for message\n",
    "    finalScore = 0\n",
    "    roundedFinalScore = 0\n",
    "\n",
    "    # variables to hold the highest positive score in the message\n",
    "    # and highest negative score in the message\n",
    "    maxPosScore = 0\n",
    "    maxNegScore = 0\n",
    "\n",
    "#     print(\"===\")\n",
    "    commentLines = tokenize.sent_tokenize(body)\n",
    "    for line in commentLines:\n",
    "        ss = sid.polarity_scores(line)\n",
    "        # uncomment these lines if you want to print out sentences & scores\n",
    "        '''\n",
    "        line = line.replace('\\n', ' ').replace('\\r', '')\n",
    "        print(line)\n",
    "        for k in sorted(ss):\n",
    "            print(' {0}: {1}\\n'.format(k,ss[k]), end='')\n",
    "        '''\n",
    "        lineCompoundScore = ss['compound']\n",
    "        finalScore += lineCompoundScore\n",
    "\n",
    "        if ss['pos'] > maxPosScore:\n",
    "            maxPosScore = ss['pos']\n",
    "        elif ss['neg'] > maxNegScore:\n",
    "            maxNegScore = ss['neg']\n",
    "\n",
    "    # roundedFinalScore is the average compound score for the entire message\n",
    "    commentLength = len(commentLines)\n",
    "    if commentLength == 0:\n",
    "        commentLength = 1\n",
    "        \n",
    "    roundedFinalScore = round(finalScore / commentLength, 4)\n",
    "    \n",
    "#     commentCount += 1\n",
    "#     if commentCount % 1000 == 0:\n",
    "#         print(commentCount)\n",
    "#         # break\n",
    "\n",
    "#     return [str(roundedFinalScore), str(maxPosScore), str(maxNegScore), subreddit]\n",
    "#     return \"{0}\\t{1}\\t{2}\\t{3}\\n\".format(roundedFinalScore, maxPosScore, maxNegScore, subreddit)   \n",
    "#     return [float(roundedFinalScore), float(maxPosScore), float(maxNegScore), subreddit]    \n",
    "#     return (float(roundedFinalScore), subreddit)   \n",
    "    return (subreddit, float(roundedFinalScore))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(subreddit='AskReddit', body='I read the title and thought of that cheating bitch clown from the glassjaw video')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiment_scores = text_all.rdd.flatMap(analyze_sentiment)\n",
    "text_all.rdd.take(1)\n",
    "# sentiment_scores.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import StructType, StructField, FloatType, StringType\n",
    "# # features = [StructField('roundedFinalScore'.strip(), StringType(), True), StructField('maxPosScore'.strip(), StringType(), True), \\\n",
    "# #                      StructField('maxNegScore'.strip(), StringType(), True), StructField('subreddit'.strip(), StringType(), True)]\n",
    "# features = [StructField('roundedFinalScore'.strip(), FloatType(), True), StructField('maxPosScore'.strip(), FloatType(), True), \\\n",
    "#                      StructField('maxNegScore'.strip(), FloatType(), True), StructField('subreddit'.strip(), StringType(), True)]\n",
    "# schema = StructType(features)\n",
    "# print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AskReddit', -0.8126)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv(string):\n",
    "    try:\n",
    "        return float(string)\n",
    "    except:\n",
    "        return 0.0\n",
    "    \n",
    "# sentiment_scores = text_all.rdd.flatMap(lambda row: [conv(r) for r in analyze_sentiment(row)]).toDF(schema)\n",
    "# sentiment_scores = text_all.rdd.flatMap(analyze_sentiment)\n",
    "sentiment_scores = text_all.rdd.map(analyze_sentiment)\n",
    "sentiment_scores.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AskReddit', -0.8126),\n",
       " ('AskReddit', 0.0),\n",
       " ('politics', -0.2552),\n",
       " ('AskReddit', -0.2384)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AskReddit', -0.8126),\n",
       " ('AskReddit', 0.0),\n",
       " ('politics', -0.2552),\n",
       " ('AskReddit', -0.2384),\n",
       " ('IAmA', 0.0979),\n",
       " ('California', 0.0),\n",
       " ('pics', 0.0),\n",
       " ('reddit.com', 0.0075),\n",
       " ('AskReddit', -0.17),\n",
       " ('AskReddit', 0.4465)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_sub = sentiment_scores.take(10)\n",
    "sentiment_scores_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[22] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AskReddit', -0.8126),\n",
       " ('AskReddit', 0.0),\n",
       " ('politics', -0.2552),\n",
       " ('AskReddit', -0.2384),\n",
       " ('IAmA', 0.0979),\n",
       " ('California', 0.0),\n",
       " ('pics', 0.0),\n",
       " ('reddit.com', 0.0075),\n",
       " ('AskReddit', -0.17),\n",
       " ('AskReddit', 0.4465)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LightNovels', 2188.2942999999977),\n",
       " ('GermanPractice', 25.700699999999994),\n",
       " ('shittyprogramming', 298.91109999999975),\n",
       " ('ghibli', 915.9782999999978),\n",
       " ('StudentLoans', 767.7833999999998),\n",
       " ('techolitics', 232.2476999999995),\n",
       " ('ewu', 14.1128),\n",
       " ('paranormalromance', 20.2458),\n",
       " ('turfing', -0.3125),\n",
       " ('PumpUpMusic', 0.5544)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: it takes time!\n",
    "sentiment_scores = sentiment_scores.reduceByKey(lambda x, y: x + y)\n",
    "sentiment_scores.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('news', -69372.80710000006),\n",
       " ('worldnews', -56732.96110000015),\n",
       " ('de', -24307.399600000015),\n",
       " ('podemos', -12112.384499999995),\n",
       " ('argentina', -11194.748800000001)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores.sortBy(lambda x: x[1]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AskReddit', 972887.5779000001),\n",
       " ('leagueoflegends', 387322.6532000008),\n",
       " ('pics', 288720.4549999993),\n",
       " ('gonewild', 275213.59609999973),\n",
       " ('gaming', 262655.0113999998)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores.sortBy(lambda x: x[1], False).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mac: 4431.5900999999985\n"
     ]
    }
   ],
   "source": [
    "for row in sentiment_scores.collect():\n",
    "    if row[0] == 'mac':\n",
    "        print('mac:', row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windows: 3270.1883999999986\n"
     ]
    }
   ],
   "source": [
    "for row in sentiment_scores.collect():\n",
    "    if row[0] == 'windows':\n",
    "        print('windows:', row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd = sc.parallelize([('a', 5), ('c', 8), ('b', 6), ('a', 8), ('b', 8), ('a', 3)])\n",
    "# rdd.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2]\n",
    "b = [3, 4]\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_all.write.saveAsTable('text_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_all.createOrReplaceTempView('text_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "  subreddit, \n",
    "  body\n",
    "FROM\n",
    "  text_all\n",
    "GROUP BY subreddit\n",
    "'''\n",
    "text_all = spark.sql(query)\n",
    "text_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = text_all.rdd.flatMap(analyze_sentiment).toDF().show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for row in text_all.rdd.collect(): \n",
    "    subreddit = row['subreddit']\n",
    "    text = row['body']\n",
    "    if subreddit in dic:\n",
    "        dic[subreddit].append(text)\n",
    "    else:\n",
    "        texts = []\n",
    "        texts.append(text)\n",
    "        dic[subreddit] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'bob'\n",
    "num = 12\n",
    "if 'bob' in dic: \n",
    "    dic[text].append(num)\n",
    "else: \n",
    "    nums = []\n",
    "    nums.append(num)\n",
    "    dic[text] = nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 15\n",
    "if 'bob' in dic: \n",
    "    dic[text].append(num)\n",
    "else: \n",
    "    nums = []\n",
    "    nums.append(num)\n",
    "    dic[text] = nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
